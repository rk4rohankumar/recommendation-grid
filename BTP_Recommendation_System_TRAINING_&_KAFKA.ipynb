{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Harshtyagi001/recommendation-grid/blob/main/BTP_Recommendation_System_TRAINING_%26_KAFKA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GEb9uCZsI983"
      },
      "source": [
        "#**PERSONALISED RECOMMENDATION SYSTEM:**\n",
        "\n",
        "We took upon the challenge to build a personalized recommender engine like that similar to e-commerce platforms like Amazon and Flipkart.\n",
        "\n",
        "Our unique spin was to try use realtime clickstream data instead of available public datasets. We tried to use Apache Kafka as a processing pipeline. Clickstream events will be ingested (collecting and importing data) by Kafka, then processed to filter out the noise and then two things will happen:\n",
        "1. The data is streamed directly to the model during the login session, allowing for the generation of instant relevant recommendations.\n",
        "2. Simultaneously, the data is stored in our database for subsequent use in model training. This stored data is provided to the model in batches.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pp4a-vxwbVJ2"
      },
      "source": [
        "# Overview\n",
        "\n",
        "In this project, we utilized collaborative filtering, a widely used technique that utilizes data on how users interact with items to offer personalized recommendations. Our system predicts user preferences for items based on their past interactions and similarities to other users.\n",
        "\n",
        "To assess our system's effectiveness, we adopted a customized evaluation metric. Our approach combines click-through rate and diversity index, enabling us to calculate the Personalized Click-Through Diversity Index (PCDI) and better measure the system's performance.\n",
        "\n",
        "As mentioned, we tried to integre Apache Kafka to collect real-time user data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "### **METHADOLOGY**\n",
        "\n",
        "Our approach involves several steps:\n",
        "\n",
        "1. Data Preprocessing: We'll preprocess the user interaction data, including clicks, add-to-cart actions, and ratings, to create a utility matrix.\n",
        "2. Collaborative Filtering: We'll train a collaborative filtering model using the Surprise library, which will learn user and item embeddings to make personalized recommendations.\n",
        "3. Evaluation: We'll evaluate the model's performance using the PCDI metric, which combines click-through rate and diversity of recommendations.\n",
        "4. Interpretation: We'll analyze the results and gain insights into the effectiveness of the recommendation system.\n",
        "\n",
        "### **Data**\n",
        "\n",
        "To tackle cold start, we used a publicly available dataset to recommend popular products. Then we planned to gather clickstream data. But since this was a daunting task, we ultimately had to simlate clickstream data by taking user input and also took the help of a Python-generated dataset with the help of faker library.\n",
        "\n",
        "Here is a flowchart of our methdology.\n",
        "\n",
        "![image](https://github.com/priyansh2120/recommendation-grid/assets/96059277/506b31c1-33d3-4607-99a1-ea5af68c2d0f)\n"
      ],
      "metadata": {
        "id": "XrWOpC7TbWiH"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KyFgnDJoZetj"
      },
      "source": [
        "## **Importing Necessary Libraries**\n",
        "\n",
        "Here is an explanation about a few libraraies we used:\n",
        "\n",
        "- **Surprise Library**: Surprise is a library for building recommendation systems. We'll use it to create collaborative filtering models and make user-product recommendations.\n",
        "\n",
        "- **SQLAlchemy and SQLite**: These libraries enable interaction with SQLite databases. We'll use them to store and retrieve data when necessary.\n",
        "\n",
        "- **Confluent Kafka**: Kafka is a streaming platform, and Confluent Kafka is a Python client for Kafka. We'll use it to simulate real-time data interactions in our recommendation system.\n",
        "\n",
        "- **Faker**: Faker is a library for generating synthetic data. We'll use it for now to create artificial user interactions for testing and development."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xas38dvWIzWL",
        "outputId": "22f0c5c8-7a51-46e6-8387-8cbec0af0f30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting surprise\n",
            "  Downloading surprise-0.1-py2.py3-none-any.whl (1.8 kB)\n",
            "Collecting confluent_kafka\n",
            "  Downloading confluent_kafka-2.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting faker\n",
            "  Downloading Faker-19.13.0-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m70.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting kafka\n",
            "  Downloading kafka-1.3.5-py2.py3-none-any.whl (207 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.2/207.2 kB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scikit-surprise (from surprise)\n",
            "  Downloading scikit-surprise-1.1.3.tar.gz (771 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m772.0/772.0 kB\u001b[0m \u001b[31m54.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: python-dateutil>=2.4 in /usr/local/lib/python3.10/dist-packages (from faker) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.4->faker) (1.16.0)\n",
            "Requirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise->surprise) (1.3.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise->surprise) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise->surprise) (1.11.3)\n",
            "Building wheels for collected packages: scikit-surprise\n",
            "  Building wheel for scikit-surprise (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scikit-surprise: filename=scikit_surprise-1.1.3-cp310-cp310-linux_x86_64.whl size=3163341 sha256=0ae85f288d8a49965e337af4ec41d1d76ca831a6c5b22500b9a32f489fab1642\n",
            "  Stored in directory: /root/.cache/pip/wheels/a5/ca/a8/4e28def53797fdc4363ca4af740db15a9c2f1595ebc51fb445\n",
            "Successfully built scikit-surprise\n",
            "Installing collected packages: kafka, confluent_kafka, scikit-surprise, faker, surprise\n",
            "Successfully installed confluent_kafka-2.3.0 faker-19.13.0 kafka-1.3.5 scikit-surprise-1.1.3 surprise-0.1\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "!pip install surprise confluent_kafka faker kafka\n",
        "from surprise import Dataset, Reader, SVD\n",
        "import sqlalchemy\n",
        "import sqlite3\n",
        "from confluent_kafka import Producer, Consumer\n",
        "from faker import Faker\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lcf5GHbYdxQO"
      },
      "source": [
        "# **Generating Synthetic Data for Testing**\n",
        "\n",
        "Obtaining real user interactions and preferences is challenging during the initial stages of development. To address this, we have created a function called `generate_synthetic_data`. We can use existing data, but our goal was to try and not use any existing dataset.\n",
        "\n",
        "**Function Purpose:**\n",
        "The `generate_synthetic_data` function leverages the Faker library to generate synthetic user interactions for testing purposes. These interactions include user clicks, product add-to-cart actions, ratings, and timestamps. The generated data will be diverse to simulate real world scenarios.\n",
        "\n",
        "***The generated data mimics real-world user behavior and allows us to validate the functionality of our recommendation system under various scenarios.***\n",
        "\n",
        "\n",
        "**Data Storage:**\n",
        "Once all interactions are generated, the function creates a Pandas DataFrame to organize the synthetic data. This DataFrame is then saved as a CSV file named 'synthetic_data.csv'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ijlUodyASSi"
      },
      "outputs": [],
      "source": [
        "def generate_synthetic_data():\n",
        "    fake = Faker()\n",
        "    # Generate synthetic user interactions\n",
        "    interactions = []\n",
        "    for _ in range(10000):\n",
        "        user_id = fake.random_int(min=1, max=100)\n",
        "        product_id = fake.random_int(min=1, max=1000)\n",
        "        click = fake.random_int(min=0, max=12)\n",
        "        add_to_cart = fake.random_element(elements=('added', 'not_added'))\n",
        "        rating = fake.random_int(min=1, max=5)\n",
        "        timestamp = fake.date_time_between(start_date='-1y', end_date='now')\n",
        "        interactions.append({\n",
        "            'user_id': user_id,\n",
        "            'product_id': product_id,\n",
        "            'click': click,\n",
        "            'add_to_cart': add_to_cart,\n",
        "            'rating': rating,\n",
        "            'timestamp': timestamp\n",
        "        })\n",
        "    # Save synthetic data as CSV\n",
        "    df = pd.DataFrame(interactions)\n",
        "    df.to_csv('synthetic_data.csv', index=False)  # index=False argument ensures that the row index is not included in the CSV file"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qEi0x2Ge0z_"
      },
      "source": [
        "To generate the synthetic data, we simply call the `generate_synthetic_data` function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-2sgf86-C2fb"
      },
      "outputs": [],
      "source": [
        "# Generate synthetic data\n",
        "generate_synthetic_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULDzLi1GeeGF"
      },
      "source": [
        "## **Creating SQLite Database and Importing Synthetic Data**\n",
        "\n",
        "We created the `create_sqlite_database` function to make an SQLite database and import the previously generated synthetic data.\n",
        "\n",
        "**Function Purpose:**\n",
        "The `create_sqlite_database` function does two things:\n",
        "1. It connects to an SQLite database named **'recommendation.db'**.\n",
        "2. It creates a table named **'user_interactions'** in the database to store user interactions like user IDs, product IDs, click actions, add-to-cart actions, ratings, and timestamps.\n",
        "\n",
        "**How It Works:**\n",
        "- The function starts by connecting to the SQLite database and getting a cursor object for executing SQL commands.\n",
        "- It defines the structure of the 'user_interactions' table with specific columns for each type of interaction.\n",
        "- The synthetic data stored in 'synthetic_data.csv' is then imported. The function uses Pandas to read the CSV file into a DataFrame and the `to_sql` method to insert the data into the 'user_interactions' table.\n",
        "- If the table exists, the new data replaces any existing data due to the 'replace' parameter.\n",
        "\n",
        "**Data Storage and Management:**\n",
        "The SQLite database acts as a central storehouse for user interaction details. This data is easily accessible for analysis, model training, and generating recommendations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m6stuYXwAr4h"
      },
      "outputs": [],
      "source": [
        "# Create SQLite database and import synthetic data\n",
        "def create_sqlite_database():\n",
        "    conn = sqlite3.connect('recommendation.db')\n",
        "    cursor = conn.cursor()\n",
        "    # Create table for user interactions\n",
        "    cursor.execute('''\n",
        "        CREATE TABLE IF NOT EXISTS user_interactions (\n",
        "            id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "            user_id INTEGER,\n",
        "            product_id INTEGER,\n",
        "            click INTEGER,\n",
        "            add_to_cart TEXT,\n",
        "            rating INTEGER,\n",
        "            timestamp DATETIME\n",
        "        )\n",
        "    ''')\n",
        "    # Import synthetic data into the table\n",
        "    df = pd.read_csv('synthetic_data.csv')\n",
        "    df.to_sql('user_interactions', conn, if_exists='replace', index=False)\n",
        "    conn.commit()\n",
        "    conn.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wChVkx-6fGtM"
      },
      "source": [
        "To create the SQLite database and import synthetic data, we once again simply call the `create_sqlite_database()` function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W3ildPlRDPYm"
      },
      "outputs": [],
      "source": [
        "# Create SQLite database and import synthetic data\n",
        "create_sqlite_database()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EqJE2IrVfL7w"
      },
      "source": [
        "### **Verifying Database Creation and Data Retrieval**\n",
        "\n",
        "To ensure the successful creation of the SQLite database, we run the following snippet. This code demonstrates how to connect to the database, extract data from the `user_interactions` table, and display the initial rows of the dataset.\n",
        "\n",
        "**Verifying Database Connection:**\n",
        "Before interacting with the database, we use the `sqlite3` module to establish a connection to the SQLite database file named `recommendation.db`.\n",
        "\n",
        "Then, we retrieve the data, close the connection, and display the first few rows to confirm the successful creation and retrieval of data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "9WzGPI5zBJvf",
        "outputId": "86c39ba1-93ae-4430-f4f4-ba90f12d8d78"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   user_id  product_id  click add_to_cart  rating            timestamp\n",
              "0       78         964     10       added       2  2023-10-13 02:47:56\n",
              "1       92         830      9   not_added       4  2023-03-22 19:40:50\n",
              "2       32         687     11       added       4  2023-05-14 19:52:16\n",
              "3       22         287      1       added       5  2023-10-03 14:53:27\n",
              "4       32         924      6   not_added       4  2023-01-27 08:32:01"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1d707003-1330-49e8-b8b3-cbfde453401e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>product_id</th>\n",
              "      <th>click</th>\n",
              "      <th>add_to_cart</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>78</td>\n",
              "      <td>964</td>\n",
              "      <td>10</td>\n",
              "      <td>added</td>\n",
              "      <td>2</td>\n",
              "      <td>2023-10-13 02:47:56</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>92</td>\n",
              "      <td>830</td>\n",
              "      <td>9</td>\n",
              "      <td>not_added</td>\n",
              "      <td>4</td>\n",
              "      <td>2023-03-22 19:40:50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>32</td>\n",
              "      <td>687</td>\n",
              "      <td>11</td>\n",
              "      <td>added</td>\n",
              "      <td>4</td>\n",
              "      <td>2023-05-14 19:52:16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>22</td>\n",
              "      <td>287</td>\n",
              "      <td>1</td>\n",
              "      <td>added</td>\n",
              "      <td>5</td>\n",
              "      <td>2023-10-03 14:53:27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>32</td>\n",
              "      <td>924</td>\n",
              "      <td>6</td>\n",
              "      <td>not_added</td>\n",
              "      <td>4</td>\n",
              "      <td>2023-01-27 08:32:01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1d707003-1330-49e8-b8b3-cbfde453401e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1d707003-1330-49e8-b8b3-cbfde453401e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1d707003-1330-49e8-b8b3-cbfde453401e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-60cab07e-1813-4540-9aa7-025b28070868\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-60cab07e-1813-4540-9aa7-025b28070868')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-60cab07e-1813-4540-9aa7-025b28070868 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# verify that dabase was created\n",
        "import sqlite3\n",
        "conn = sqlite3.connect('recommendation.db')\n",
        "df = pd.read_sql_query('SELECT * FROM user_interactions', conn)\n",
        "conn.close()\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3QP9izgNiMz3"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# **Kafka Configuration for Click Stream Producer**\n",
        "\n",
        "In this code snippet, we define a configuration dictionary called `kafka_config` that configures the Kafka producer. The producer is responsible for sending click stream events to a specific Kafka topic. A Kafka topic is a specific category to which records are published. The configuration dictionary includes two key-value pairs:\n",
        "\n",
        "1. `'bootstrap.servers'`: This specifies the address and port of the Kafka broker (server that facilitates the communication between the producers and consumers).\n",
        "\n",
        "2. `'client.id'`: This sets an identifier for the Kafka producer. In this case, it is set to `'clickstream-producer'`, serving as a unique name to identify the producer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n0txDj0PiLlX"
      },
      "outputs": [],
      "source": [
        "kafka_config = {\n",
        "    'bootstrap.servers': 'localhost:9092',\n",
        "    'client.id': 'clickstream-producer'\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUmZR348hhwA"
      },
      "source": [
        "## **Simulating Click Stream Events and Adding to DataFrame**\n",
        "\n",
        "In this section, we will simulate capturing multiple click stream events and then add these events to an existing DataFrame. Lack of technical knowledge  and financial limitations along with no real user database has made us simulate click stream events rather than capture them like we said we would.\n",
        "\n",
        "Each click stream event will be represented by a `ClickStreamEvent` object, containing information such as user ID, product ID, click status, add-to-cart status, rating, and timestamp. Then this simulated data is added to an existing DataFrame for further analysis and processing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9tyrTbXvKm5p",
        "outputId": "3ab71005-ee93-422a-f3f0-8dfc836c4864"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter the number of click stream events: 1\n",
            "Enter user ID: 23\n",
            "Enter product ID: 123\n",
            "Enter the number of clicks: 2\n",
            "Did the user add to cart? (yes/no): no\n",
            "Enter rating (if given): 1\n",
            "Enter timestamp (YYYY-MM-DD HH:MM:SS): 2023:12:23 11:22:23\n"
          ]
        }
      ],
      "source": [
        "from datetime import datetime\n",
        "import time\n",
        "import pandas as pd\n",
        "\n",
        "class ClickStreamEvent:\n",
        "    def __init__(self, user_id, product_id, click, add_to_cart, rating, timestamp):\n",
        "        self.user_id = user_id\n",
        "        self.product_id = product_id\n",
        "        self.click = click\n",
        "        self.add_to_cart = add_to_cart\n",
        "        self.rating = rating\n",
        "        self.timestamp = timestamp\n",
        "\n",
        "# Simulate capturing multiple click stream events\n",
        "click_stream_events = []\n",
        "\n",
        "num_events = int(input(\"Enter the number of click stream events: \"))\n",
        "\n",
        "for _ in range(num_events):\n",
        "    user_id = input(\"Enter user ID: \")\n",
        "    product_id = input(\"Enter product ID: \")\n",
        "    click = int(input(\"Enter the number of clicks: \"))  # Modified to accept the number of clicks as an integer\n",
        "    add_to_cart = input(\"Did the user add to cart? (yes/no): \").lower() == \"yes\"\n",
        "    rating = int(input(\"Enter rating (if given): \"))\n",
        "    timestamp = input(\"Enter timestamp (YYYY-MM-DD HH:MM:SS): \")\n",
        "\n",
        "    event = ClickStreamEvent(user_id, product_id, click, add_to_cart, rating, timestamp)\n",
        "    click_stream_events.append(event)\n",
        "\n",
        "rows = []\n",
        "for event in click_stream_events:\n",
        "    new_row = {\n",
        "        'user_id': event.user_id,\n",
        "        'product_id': event.product_id,\n",
        "        'click': event.click,\n",
        "        'add_to_cart': event.add_to_cart,\n",
        "        'rating': event.rating,\n",
        "        'timestamp': event.timestamp\n",
        "    }\n",
        "    rows.append(new_row)\n",
        "\n",
        "df = pd.concat([df, pd.DataFrame(rows)], ignore_index=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjEhVc3jlweI"
      },
      "source": [
        "### **Sending Click Stream Events to Kafka**\n",
        "\n",
        "This section demonstrates how to use a Kafka producer to send simulated click stream events to a Kafka topic for further processing and analysis. The click stream events will be serialized into JSON format and then sent to the Kafka topic named `click_stream_topic`.\n",
        "\n",
        "1. **Creating Kafka Producer**: We first create a Kafka producer using the provided `kafka_config` dictionary. The producer will be responsible for sending the click stream events to the Kafka topic.\n",
        "\n",
        "2. **Processing and Sending Events**: We use a loop to iterate through the list of `click_stream_events`. For each event, we create a dictionary `event_data` containing the attributes of the event such as user ID, product ID, click status, add-to-cart status, rating, and timestamp. We then serialize this dictionary into JSON format using the `json.dumps()` function.\n",
        "\n",
        "3. **Sending to Kafka**: Using the Kafka producer, we send the serialized event data to the `click_stream_topic` Kafka topic. We also use `producer.flush()` to ensure that the message is sent immediately.\n",
        "\n",
        "4. **Print and Delay**: After sending each event, we print a message confirming the sent event's data and use `time.sleep(1)` to introduce a delay of 1 second before processing the next event.\n",
        "\n",
        "5. **Closing the Producer**: Once all events are sent, we close the Kafka producer using the `producer.close()` method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FjkT29X9k7Ln",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d39c491c-741f-407e-89dc-3f2dc157f2c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sent click stream event to Kafka: {'user_id': '54', 'product_id': '666', 'click': 4, 'add_to_cart': False, 'rating': 2, 'timestamp': '2023-12-12 11:23:23'}\n",
            "--------------------\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "# Create Kafka producer\n",
        "producer = Producer(kafka_config)\n",
        "\n",
        "# Process and send the list of click stream events to Kafka\n",
        "for event in click_stream_events:\n",
        "    # Serialize event data\n",
        "    event_data = {\n",
        "        'user_id': event.user_id,\n",
        "        'product_id': event.product_id,\n",
        "        'click': event.click,\n",
        "        'add_to_cart': event.add_to_cart,\n",
        "        'rating': event.rating,\n",
        "        'timestamp': event.timestamp\n",
        "    }\n",
        "    serialized_event = json.dumps(event_data)\n",
        "\n",
        "    # Send event data to Kafka topic\n",
        "    producer.produce('click_stream_topic', value=serialized_event.encode('utf-8'))\n",
        "    producer.flush()\n",
        "    print(\"Sent click stream event to Kafka:\", event_data)\n",
        "    print(\"-\" * 20)\n",
        "\n",
        "    # Simulate some delay before processing the next event\n",
        "    time.sleep(1)  # Adjust the delay as needed\n",
        "\n",
        "# Flush any outstanding messages and close the Kafka producer\n",
        "producer.flush()\n",
        "producer = None  # Set the producer object to None to release its resources"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GV_cr_75mUAC"
      },
      "source": [
        "\n",
        "### **Processing Click Stream Events**\n",
        "\n",
        "In this section, we will process and display the details of the received click stream events that were previously sent to the Kafka topic. We iterate through the `click_stream_events` list and print out the attributes of each event, including user ID, product ID, click status, add-to-cart status, rating, and timestamp."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eH4lcE5Wk9t7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1dc6fd60-1aaa-4ece-d92a-bca9fc4a5ccf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Received click stream event:\n",
            "User ID: 54\n",
            "Product ID: 666\n",
            "Click: 4\n",
            "Add to Cart: False\n",
            "Rating: 2\n",
            "Timestamp: 2023-12-12 11:23:23\n",
            "--------------------\n"
          ]
        }
      ],
      "source": [
        "# Process the list of click stream events\n",
        "for event in click_stream_events:\n",
        "    print(\"Received click stream event:\")\n",
        "    print(\"User ID:\", event.user_id)\n",
        "    print(\"Product ID:\", event.product_id)\n",
        "    print(\"Click:\", event.click)\n",
        "    print(\"Add to Cart:\", event.add_to_cart)\n",
        "    print(\"Rating:\", event.rating)\n",
        "    print(\"Timestamp:\", event.timestamp)\n",
        "    print(\"-\" * 20)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we add the processed clickstream data into our databse."
      ],
      "metadata": {
        "id": "tQ_RDRiRIAFD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kDB9h67tooTF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e687b17-863f-499e-b679-ffc594c0fd82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated clickstream events have been added to the database.\n"
          ]
        }
      ],
      "source": [
        "# Append the generated clickstream events to the database\n",
        "conn = sqlite3.connect('recommendation.db')\n",
        "cursor = conn.cursor()\n",
        "\n",
        "for event in click_stream_events:\n",
        "    cursor.execute('''\n",
        "        INSERT INTO user_interactions (user_id, product_id, click, add_to_cart, rating, timestamp)\n",
        "        VALUES (?, ?, ?, ?, ?, ?)\n",
        "    ''', (event.user_id, event.product_id, event.click, event.add_to_cart, event.rating, event.timestamp))\n",
        "\n",
        "conn.commit()\n",
        "conn.close()\n",
        "\n",
        "print(\"Generated clickstream events have been added to the database.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yMO_SFlyrcc2"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "##**Collaborative Filtering and K-Nearest Neighbors (KNN) Recommendation System**\n",
        "\n",
        "In this section, we'll build a recommendation system using collaborative filtering and the K-Nearest Neighbors (KNN) algorithm. Collaborative filtering is a widely used in recommendation systems that predicts a user's preferences based on the preferences of similar users. KNN, on the other hand, is a method that identifies the 'k' nearest neighbors to a particular user, and uses their preferences to make ranked recommendations.\n",
        "\n",
        "We'll utilize the Surprise library for building and analyzing the  recommender system.\n",
        "\n",
        "Here, we begin by importing the necessary libraries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3OFz3GirrEfU"
      },
      "outputs": [],
      "source": [
        "from surprise import SVD, Dataset, Reader, KNNBasic\n",
        "from surprise.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "from datetime import datetime"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IfQ2Y4N-rokq"
      },
      "source": [
        "### **Loading Data for Collaborative Filtering**\n",
        "\n",
        "In this section, we'll discuss the process of loading data for collaborative filtering, a popular technique used in recommendation systems. Collaborative filtering involves making automatic predictions (filtering) about the interests of a user by collecting preferences from many users (collaborating).\n",
        "\n",
        "We'll utilize the Surprise library to load and preprocess our data.\n",
        "\n",
        "The code snippet demonstrates how to load data for collaborative filtering using the `load_data_for_collaborative_filtering` function.\n",
        "\n",
        "This function takes a DataFrame (`df`) as input, which contains user interactions. The `Reader` class is used to specify the rating scale (here, between 1 and 5).\n",
        "\n",
        "The `Dataset.load_from_df` method from the Surprise library is then used to load the data into a Surprise-compatible format. This format is crucial for training and evaluating collaborative filtering models. The loaded data is returned as a `data` object."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U79l8DeLrm2l"
      },
      "outputs": [],
      "source": [
        "# Load data for collaborative filtering\n",
        "def load_data_for_collaborative_filtering(df):\n",
        "    reader = Reader(rating_scale=(1, 5))\n",
        "    data = Dataset.load_from_df(df[['user_id', 'product_id', 'rating']], reader)\n",
        "    return data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBda5mQNsBJ4"
      },
      "source": [
        "### **Splitting Data into Training and Testing Sets**\n",
        "\n",
        "The next step is to split it into training and testing sets.\n",
        "\n",
        "The code snippet demonstrates how to split the data into training and testing sets using the `split_data` function. The `data` object, loaded in the previous step, is used as input. The `train_test_split` function from the Surprise library is employed for this purpose.\n",
        "\n",
        "The function returns two sets: `trainset` and `testset`. The `trainset` is used for training our collaborative filtering model, while the `testset` is used to evaluate the model's performance. The parameter `test_size` specifies the proportion of data allocated for testing (in this case, 20% of the data).\n",
        "\n",
        "It's important to note that setting a `random_state` ensures reproducibility in the data split, allowing us to obtain consistent results across different runs. Simply put, it controls the shuffling of data before it is split."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R7WlemcBsJ8F"
      },
      "outputs": [],
      "source": [
        "# Split data into training and testing sets\n",
        "def split_data(data):\n",
        "    trainset, testset = train_test_split(data, test_size=0.2, random_state=42)\n",
        "    return trainset, testset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BXiTPPUIsNUh"
      },
      "source": [
        "## **Training Collaborative Filtering Model**\n",
        "\n",
        "The next step is to train a collaborative filtering model.\n",
        "\n",
        "Within the function, we create an instance of the Singular Value Decomposition (SVD) model using `SVD()` from the Surprise library. SVD is a matrix factorization technique commonly used for collaborative filtering. We then fit the model to the training data using the `fit` method.\n",
        "\n",
        "The trained model is returned, which can be used to generate recommendations for users based on their interactions and preferences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S_HXUM-lsYLZ"
      },
      "outputs": [],
      "source": [
        "# Train collaborative filtering model\n",
        "def train_collaborative_filtering_model(trainset):\n",
        "    model = SVD()\n",
        "    model.fit(trainset)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cpsf78pBsdpv"
      },
      "source": [
        "## **Generating Unranked Recommendations using Collaborative Filtering**\n",
        "\n",
        "After training the collaborative filtering model, we can proceed to generate unranked recommendations for a specific user. Unranked recommendations are a list of items that the model suggests as potential options for the user to consider.\n",
        "\n",
        "Inside the function, we access the user's interactions in the `trainset` using `trainset.ur[trainset.to_inner_uid(user_id)]`. For each item the user has interacted with, we retrieve its inner item ID and convert it back to the original product ID using `trainset.to_raw_iid(inner_iid)`. These product IDs form the list of unranked recommendations.\n",
        "\n",
        "*Inner ID refers to the unique numerical identifier assigned to each user or item within the data structure used by the Surprise library. This helps the library perform compputations smoothly. We have to convert the inner ID back to theoriginal value so that we can stay true to the values in the database*\n",
        "\n",
        "These unranked recommendations provide an initial set of items that the user might be interested in, based on their past interactions. However, these recommendations are not yet ranked by relevance or preference."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "294rvaIZsryp"
      },
      "outputs": [],
      "source": [
        "# Generate unranked recommendations based on collaborative filtering model\n",
        "def generate_unranked_recommendations(model, user_id, trainset):\n",
        "    user_items = list(trainset.ur[trainset.to_inner_uid(user_id)])\n",
        "    recommendations = []\n",
        "    for inner_iid, _ in user_items:\n",
        "        product_id = trainset.to_raw_iid(inner_iid)\n",
        "        recommendations.append(product_id)\n",
        "    return recommendations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3S721imPsxE0"
      },
      "source": [
        "\n",
        "## **Training a K-Nearest Neighbors (KNN) Model**\n",
        "\n",
        "In addition to collaborative filtering, another recommendation technique we used is the K-Nearest Neighbors (KNN) algorithm. The KNN algorithm uses the similarity between users or items to make recommendations.\n",
        "\n",
        "Inside the function, we specify the `sim_options` parameter, where we choose the similarity metric to be the cosine similarity. Additionally, we set `user_based` to `False`, indicating that we are using item-based similarity. The model is then trained on the `trainset`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gfTP-6BBs6KT"
      },
      "outputs": [],
      "source": [
        "# Train KNN model\n",
        "def train_knn_model(trainset):\n",
        "    sim_options = {\n",
        "        'name': 'cosine',\n",
        "        'user_based': False\n",
        "    }\n",
        "    model = KNNBasic(sim_options=sim_options)\n",
        "    model.fit(trainset)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rpYqcmB2tOqd"
      },
      "source": [
        "\n",
        "### **Generating Ranked Recommendations using K-Nearest Neighbors (KNN) Model**\n",
        "\n",
        "The next step is to generate ranked recommendations using this model.\n",
        "\n",
        "We define the `generate_ranked_knn_recommendations` function, which takes the trained KNN `model` and a list of `unranked_recommendations` as input. The unranked recommendations are the items that the collaborative filtering model has suggested.\n",
        "\n",
        "Inside the function, we iterate through each `product_id` in the `unranked_recommendations` list. For each product, we map the `product_id` to its corresponding inner item ID using `model.trainset.to_inner_iid(product_id)`.\n",
        "\n",
        "We then retrieve the similarity score between the given item and its neighbors from the KNN model using `model.sim[inner_iid]`. In this implementation, we use the first element of the similarity array for sorting, assuming that it represents the most relevant similarity score.\n",
        "\n",
        "The recommendations are sorted in descending order of similarity, ensuring that items with higher similarity scores are ranked higher. Finally, we return a list of the recommended item IDs in ranked order."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cFWWOCVetbAb"
      },
      "outputs": [],
      "source": [
        "# Generate ranked recommendations using KNN model\n",
        "def generate_ranked_knn_recommendations(model, unranked_recommendations):\n",
        "    knn_ranked_recommendations = []\n",
        "    for product_id in unranked_recommendations:\n",
        "        inner_iid = model.trainset.to_inner_iid(product_id)\n",
        "        # Use the first element of the similarity array for sorting\n",
        "        similarity_score = model.sim[inner_iid][0]\n",
        "        knn_ranked_recommendations.append((inner_iid, similarity_score))\n",
        "    knn_ranked_recommendations.sort(key=lambda x: x[1], reverse=True)  # Sort by similarity in descending order\n",
        "    return [item_id for item_id, _ in knn_ranked_recommendations]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZ1wZ5Hytm9O"
      },
      "source": [
        "### **Data Preprocessing**\n",
        "We have now defined all the relavant functions. Now, before training any recommendation models, it's crucial to preprocess the user interaction data to ensure it's in the right format for analysis. The following preprocessing steps are applied to the dataset:\n",
        "\n",
        "1. **Timestamp Conversion:**\n",
        "   The timestamps in the dataset are converted from string format to datetime format using the `pd.to_datetime` function.\n",
        "\n",
        "2. **Mapping Add-to-Cart:**\n",
        "   To simplify the analysis and modeling, the 'add_to_cart' columns are mapped to binary values. Specifically, 'added' values in the 'add_to_cart' column are mapped to 1 (indicating an item was added to the cart), and 'not_added' values are mapped to 0.\n",
        "\n",
        "By converting timestamps and mapping categorical variables to binary values, we create a structured and standardized dataset for recommendation analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l5dY-2H7tu2U"
      },
      "outputs": [],
      "source": [
        "# Preprocess timestamp to datetime format\n",
        "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
        "\n",
        "# Map add_to_cart to binary values\n",
        "df['add_to_cart'] = df['add_to_cart'].map({'added': 1, 'not_added': 0})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qzLuhMWLuMZp"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# **Converting Data to Surprise-Compatible Format**\n",
        "\n",
        "To effectively train and evaluate recommendation models using the Surprise library, the user interaction data needs to be converted into a format compatible with Surprise. The following steps outline this conversion process:\n",
        "\n",
        "1. **Initializing Reader:**\n",
        "   The `Reader` class from the Surprise library is used to specify the rating scale. In this case, the rating scale is set to be between 1 and 5.\n",
        "\n",
        "2. **Loading Data from DataFrame:**\n",
        "   The `Dataset.load_from_df` function is employed to load the data from the `df` DataFrame, containing columns 'user_id', 'product_id', and 'rating'. This creates a Surprise `Dataset` object that encapsulates the user-item interactions.\n",
        "\n",
        "3. **Building Trainset:**\n",
        "   The `build_full_trainset()` method is called on the `Dataset` object to construct a Surprise `Trainset`. This trainset includes all user-item interactions from the original DataFrame and is suitable for training collaborative filtering models.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yxjLTT3JuP4U"
      },
      "outputs": [],
      "source": [
        "# Convert the 'df' DataFrame to Surprise-compatible format\n",
        "reader = Reader(rating_scale=(1, 5))\n",
        "data = Dataset.load_from_df(df[['user_id', 'product_id', 'rating']], reader)\n",
        "trainset = data.build_full_trainset()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we simply start calling the functions to train our models."
      ],
      "metadata": {
        "id": "VEeB8fZpT0zf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ibruGPaeudDv"
      },
      "outputs": [],
      "source": [
        "# Train collaborative filtering model\n",
        "collab_model = train_collaborative_filtering_model(trainset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKuv0TH_uo_5"
      },
      "source": [
        "## **Generating Unranked Recommendations**\n",
        "\n",
        "Let's take a closer look at how we can generate unranked recommendations for a specific user using the trained collaborative filtering model.\n",
        "\n",
        "**Step 1: Define Example User**\n",
        "We choose an example user for whom we want to generate unranked recommendations. In this case, the `example_user_id` is set to 60.\n",
        "\n",
        "**Step 2: Generating Unranked Recommendations**\n",
        "We call the `generate_unranked_recommendations()` function, passing the following arguments:\n",
        "- `collab_model`: The collaborative filtering model trained using the SVD algorithm.\n",
        "- `example_user_id`: The ID of the user for whom we want to generate recommendations.\n",
        "- `trainset`: The training dataset used to train the collaborative filtering model.\n",
        "\n",
        "The function returns a list of unranked recommendations for the specified user. These recommendations are based on the items that the user has interacted with in the past, as learned by the collaborative filtering model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3l8X6Skvugyx"
      },
      "outputs": [],
      "source": [
        "# Example user for generating unranked recommendations\n",
        "example_user_id = 60\n",
        "unranked_recommendations = generate_unranked_recommendations(collab_model, example_user_id, trainset)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's look at the unranked recommendations for this user. These unranked recommendations represent items that the user is likely to be interested in based on their interactions with the system. However, they have not been sorted or ranked according to any specific criteria.\n"
      ],
      "metadata": {
        "id": "jzMx1y_-UqZw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zc_1N2_MnsTK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f8fb63d-543f-4127-be86-2434b5b5bec4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unranked Recommendations from Collaborative Filtering for user 60:\n",
            "Product 502\n",
            "Product 326\n",
            "Product 736\n",
            "Product 670\n",
            "Product 144\n",
            "Product 925\n",
            "Product 788\n",
            "Product 321\n",
            "Product 424\n",
            "Product 426\n",
            "Product 920\n",
            "Product 467\n",
            "Product 71\n",
            "Product 927\n",
            "Product 804\n",
            "Product 774\n",
            "Product 684\n",
            "Product 58\n",
            "Product 26\n",
            "Product 922\n",
            "Product 621\n",
            "Product 268\n",
            "Product 118\n",
            "Product 965\n",
            "Product 769\n",
            "Product 296\n",
            "Product 304\n",
            "Product 479\n",
            "Product 103\n",
            "Product 545\n",
            "Product 798\n",
            "Product 115\n",
            "Product 75\n",
            "Product 189\n",
            "Product 777\n",
            "Product 340\n",
            "Product 534\n",
            "Product 454\n",
            "Product 26\n",
            "Product 935\n",
            "Product 85\n",
            "Product 323\n",
            "Product 383\n",
            "Product 77\n",
            "Product 793\n",
            "Product 636\n",
            "Product 440\n",
            "Product 888\n",
            "Product 342\n",
            "Product 143\n",
            "Product 339\n",
            "Product 629\n",
            "Product 458\n",
            "Product 251\n",
            "Product 970\n",
            "Product 622\n",
            "Product 636\n",
            "Product 753\n",
            "Product 666\n",
            "Product 873\n",
            "Product 671\n",
            "Product 496\n",
            "Product 246\n",
            "Product 578\n",
            "Product 677\n",
            "Product 496\n",
            "Product 671\n",
            "Product 50\n",
            "Product 320\n",
            "Product 226\n",
            "Product 636\n",
            "Product 909\n",
            "Product 764\n",
            "Product 771\n",
            "Product 127\n",
            "Product 937\n",
            "Product 211\n",
            "Product 631\n",
            "Product 805\n",
            "Product 102\n",
            "Product 549\n",
            "Product 696\n",
            "Product 190\n",
            "Product 771\n",
            "Product 622\n",
            "Product 474\n",
            "Product 165\n",
            "Product 342\n",
            "Product 71\n",
            "Product 484\n",
            "Product 120\n",
            "Product 489\n",
            "Product 141\n",
            "Product 560\n",
            "Product 685\n",
            "Product 218\n",
            "Product 357\n",
            "Product 195\n",
            "Product 198\n"
          ]
        }
      ],
      "source": [
        "print(f\"Unranked Recommendations from Collaborative Filtering for user {example_user_id}:\")\n",
        "for product_id in unranked_recommendations:\n",
        "    print(f\"Product {product_id}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ChiEBgouzGp"
      },
      "source": [
        "## **Training K-Nearest Neighbors (KNN) Model and Generating Ranked Recommendations**\n",
        "\n",
        "The KNN algorithm is particularly useful for finding items that are similar to those already interacted with by the user, thereby improving recommendation quality.\n",
        "\n",
        "**Step 1: Training the KNN Model**\n",
        "We use the `train_knn_model()` function to train the KNN model.\n",
        "\n",
        "**Step 2: Generating Ranked Recommendations using KNN**\n",
        "We proceed to generate ranked recommendations using the `generate_ranked_knn_recommendations()` function. This function takes two arguments:\n",
        "- `knn_model`: The KNN model trained in the previous step.\n",
        "- `unranked_recommendations`: The list of unranked recommendations obtained from the collaborative filtering model.\n",
        "\n",
        "For each item in the list of unranked recommendations, the function calculates its similarity score based on the KNN model's similarity matrix. The recommendations are then sorted based on the similarity score in descending order to create a list of ranked recommendations. These ranked recommendations can provide users with more relevant and similar items based on their previous interactions and preferences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OlqHAS7Zu3OV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77ba71ad-1186-4d48-b961-71d4260218ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n"
          ]
        }
      ],
      "source": [
        "# Train KNN model\n",
        "knn_model = train_knn_model(trainset)\n",
        "\n",
        "# Generate ranked recommendations using KNN model\n",
        "knn_ranked_recommendations = generate_ranked_knn_recommendations(knn_model, unranked_recommendations)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's look at the ranked recommendations now."
      ],
      "metadata": {
        "id": "1rT0-jvHVDXP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qK-LxQhspMx9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5292d185-6c9e-4a77-afe6-908d9f0f30b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ranked KNN Recommendations for user 60:\n",
            "Rank 1: Product 736\n",
            "Rank 2: Product 144\n",
            "Rank 3: Product 321\n",
            "Rank 4: Product 467\n",
            "Rank 5: Product 769\n",
            "Rank 6: Product 296\n",
            "Rank 7: Product 304\n",
            "Rank 8: Product 479\n",
            "Rank 9: Product 798\n",
            "Rank 10: Product 75\n",
            "Rank 11: Product 777\n",
            "Rank 12: Product 454\n",
            "Rank 13: Product 383\n",
            "Rank 14: Product 888\n",
            "Rank 15: Product 339\n",
            "Rank 16: Product 970\n",
            "Rank 17: Product 246\n",
            "Rank 18: Product 320\n",
            "Rank 19: Product 937\n",
            "Rank 20: Product 631\n",
            "Rank 21: Product 190\n",
            "Rank 22: Product 474\n",
            "Rank 23: Product 484\n",
            "Rank 24: Product 120\n",
            "Rank 25: Product 489\n",
            "Rank 26: Product 560\n",
            "Rank 27: Product 357\n",
            "Rank 28: Product 426\n",
            "Rank 29: Product 268\n",
            "Rank 30: Product 143\n",
            "Rank 31: Product 753\n",
            "Rank 32: Product 804\n",
            "Rank 33: Product 666\n",
            "Rank 34: Product 965\n",
            "Rank 35: Product 677\n",
            "Rank 36: Product 684\n",
            "Rank 37: Product 118\n",
            "Rank 38: Product 342\n",
            "Rank 39: Product 342\n",
            "Rank 40: Product 670\n",
            "Rank 41: Product 629\n",
            "Rank 42: Product 440\n",
            "Rank 43: Product 496\n",
            "Rank 44: Product 496\n",
            "Rank 45: Product 935\n",
            "Rank 46: Product 578\n",
            "Rank 47: Product 103\n",
            "Rank 48: Product 141\n",
            "Rank 49: Product 502\n",
            "Rank 50: Product 218\n",
            "Rank 51: Product 127\n",
            "Rank 52: Product 189\n",
            "Rank 53: Product 925\n",
            "Rank 54: Product 458\n",
            "Rank 55: Product 788\n",
            "Rank 56: Product 226\n",
            "Rank 57: Product 326\n",
            "Rank 58: Product 58\n",
            "Rank 59: Product 340\n",
            "Rank 60: Product 771\n",
            "Rank 61: Product 771\n",
            "Rank 62: Product 251\n",
            "Rank 63: Product 534\n",
            "Rank 64: Product 323\n",
            "Rank 65: Product 774\n",
            "Rank 66: Product 671\n",
            "Rank 67: Product 671\n",
            "Rank 68: Product 920\n",
            "Rank 69: Product 622\n",
            "Rank 70: Product 622\n",
            "Rank 71: Product 805\n",
            "Rank 72: Product 102\n",
            "Rank 73: Product 77\n",
            "Rank 74: Product 922\n",
            "Rank 75: Product 198\n",
            "Rank 76: Product 195\n",
            "Rank 77: Product 636\n",
            "Rank 78: Product 636\n",
            "Rank 79: Product 636\n",
            "Rank 80: Product 873\n",
            "Rank 81: Product 685\n",
            "Rank 82: Product 764\n",
            "Rank 83: Product 621\n",
            "Rank 84: Product 115\n",
            "Rank 85: Product 26\n",
            "Rank 86: Product 26\n",
            "Rank 87: Product 696\n",
            "Rank 88: Product 793\n",
            "Rank 89: Product 909\n",
            "Rank 90: Product 549\n",
            "Rank 91: Product 424\n",
            "Rank 92: Product 71\n",
            "Rank 93: Product 71\n",
            "Rank 94: Product 211\n",
            "Rank 95: Product 85\n",
            "Rank 96: Product 545\n",
            "Rank 97: Product 165\n",
            "Rank 98: Product 927\n",
            "Rank 99: Product 50\n"
          ]
        }
      ],
      "source": [
        "print(f\"Ranked KNN Recommendations for user {example_user_id}:\")\n",
        "for rank, item_id in enumerate(knn_ranked_recommendations, start=1):\n",
        "    print(f\"Rank {rank}: Product {trainset.to_raw_iid(item_id)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bE92_MMQvrbA"
      },
      "source": [
        "##**Simulating User Interaction Data for Recommendation Evaluation**\n",
        "In this section, we will simulate user interaction data to showcase the evaluation of recommendation systems using various metrics. We will generate synthetic data that simulates user interactions with products, including attributes such as user ID, product ID, clicks, ratings, and timestamps.\n",
        "\n",
        "The purpose of generating this synthetic data is to provide a realistic context for evaluating recommendation algorithms and their performance. By having simulated user interactions, we can demonstrate how different evaluation metrics work and evaluate recommendation models' effectiveness."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fph1T7Tyvtzp"
      },
      "outputs": [],
      "source": [
        "# Simulated data for demonstration\n",
        "def generate_fake_data(num_users, num_items):\n",
        "    fake = Faker()\n",
        "    data = []\n",
        "    for _ in range(num_users):\n",
        "        user_id = fake.random_int(min=1, max=num_users, step=1)\n",
        "        product_id = fake.random_int(min=1, max=num_items, step=1)\n",
        "        click = fake.random_int(min=0, max=12)\n",
        "        added_to_cart = fake.random_element(elements=('yes', 'no'))\n",
        "        rating = fake.random_int(min=1, max=5, step=1)\n",
        "        timestamp = fake.date_time_between(start_date='-30d', end_date='now')\n",
        "        data.append({'user_id': user_id, 'product_id': product_id, 'click': click, 'added_to_cart': added_to_cart, 'rating': rating, 'timestamp': timestamp})\n",
        "    return data\n",
        "\n",
        "# Simulate generating data\n",
        "sample_data = generate_fake_data(num_users=100, num_items=200)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aqSoescVwz0f"
      },
      "source": [
        "###**Calculating Personalized Click-Through Diversity Index (PCDI)**\n",
        "\n",
        "In this section of the code, we implement the calculation of the Personalized Click-Through Diversity Index (PCDI), an evaluation metric for recommendation systems that combines both click-through rate (CTR) and diversity of recommended items.\n",
        "\n",
        "1. **Calculate CTR (Click-Through Rate):**\n",
        "The function `calculate_ctr` computes the CTR, which represents the ***ratio of clicked recommended items to the total number of recommended items.***\n",
        "\n",
        "2. **Calculate Diversity Score:**\n",
        "The function `calculate_diversity_score` calculates the diversity score of the clicked items based on their embeddings. It uses cosine similarity to measure the diversity of the clicked items' embeddings. The lower the similarity, the more diverse the clicked items are.\n",
        "\n",
        "*Embeddings refers to the representation of items in a multi-dimensional space, where each dimension captures a distinct feature of the item. These embeddings help the system to understand the similarities or dissimilarities among items, enabling accurate recommendations based on the item properties.*\n",
        "\n",
        "\n",
        "3. **Calculate PCDI (Personalized Click-Through Diversity Index):**\n",
        "The function `calculate_pcdi` combines the CTR and diversity score to compute the final PCDI metric. It allows specifying weights for CTR and diversity, which can be adjusted based on the importance assigned to each aspect. The function takes CTR, diversity score, and optional weights as input and returns the PCDI.\n",
        "\n",
        "These calculations are integral for evaluating recommendation models that aim to balance user engagement (CTR) with diversity of recommended items."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6XWIOSSTw-bk"
      },
      "outputs": [],
      "source": [
        "# Calculate CTR\n",
        "def calculate_ctr(clicked_items, total_recommended_items):\n",
        "    return len(clicked_items) / total_recommended_items\n",
        "\n",
        "# Calculate Diversity Score\n",
        "def calculate_diversity_score(clicked_items_embeddings):\n",
        "    similarity_matrix = cosine_similarity(clicked_items_embeddings)\n",
        "    diversity_score = 1 - np.mean(similarity_matrix)\n",
        "    return diversity_score\n",
        "\n",
        "# Calculate PCDI\n",
        "def calculate_pcdi(ctr, diversity_score, weight_ctr=0.5, weight_diversity=0.5):\n",
        "    return (ctr * weight_ctr) + (diversity_score * weight_diversity)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQu2P9-JxM9S"
      },
      "source": [
        "**Calculating PCDI for Evaluating Recommendations**\n",
        "\n",
        "In this part of the code, we proceed with calculating the Personalized Click-Through Diversity Index (PCDI) for evaluating the performance of our recommendation system.\n",
        "\n",
        "1. **Generate Clicked Items List and Item Embeddings:**\n",
        "The code first generates a list called `clicked_items` containing the product IDs of items that have been clicked by users. This is achieved by iterating through the sample data and selecting items with 'clicked' status as 'yes'. Additionally, we simulate item embeddings by creating a random matrix (`clicked_items_embeddings`) where each row represents an item and the columns represent the embedding dimensions. These embeddings would ideally represent the characteristics of the items.\n",
        "\n",
        "2. **Define Total Recommended Items:**\n",
        "The `total_recommended_items` variable is set to the total number of items that were recommended to users.\n",
        "\n",
        "3. **Calculate CTR (Click-Through Rate):**\n",
        "The `calculate_ctr` function is applied to calculate the Click-Through Rate (CTR). ***This metric reflects the proportion of recommended items that users actually engaged with***.\n",
        "\n",
        "4. **Calculate Diversity Score:**\n",
        "The `calculate_diversity_score` function is used to calculate the diversity score of the clicked items. A lower similarity score indicates higher diversity among the clicked items.\n",
        "\n",
        "By combining these metrics using the `calculate_pcdi` function, we can evaluate the recommendation system's performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x0GxPGDgxSUn"
      },
      "outputs": [],
      "source": [
        "# Process data to calculate PCDI\n",
        "clicked_items = [item['product_id'] for item in sample_data if item['click'] > 0]\n",
        "\n",
        "clicked_items_embeddings = np.random.rand(len(clicked_items), 10)\n",
        "\n",
        "total_recommended_items = 80\n",
        "\n",
        "# Calculate CTR\n",
        "ctr = calculate_ctr(clicked_items, total_recommended_items)\n",
        "\n",
        "# Calculate Diversity Score\n",
        "diversity_score = calculate_diversity_score(clicked_items_embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GHucJXSGxdrk"
      },
      "source": [
        "###**Calculating PCDI**\n",
        "\n",
        "In this part of the code, we finalize the calculation of the Personalized Click-Through Diversity Index (PCDI) by considering the weights assigned to the Click-Through Rate (CTR) and Diversity Score."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "frAoKRoEcf17",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04fd4365-54b6-408e-f96b-8b690f494dde"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CTR: 1.18\n",
            "Diversity Score: 0.23\n",
            "PCDI: 1.08\n"
          ]
        }
      ],
      "source": [
        "# Calculate PCDI\n",
        "weight_ctr = 0.90\n",
        "weight_diversity = 0.10\n",
        "pcdi = calculate_pcdi(ctr, diversity_score, weight_ctr, weight_diversity)\n",
        "\n",
        "print(f\"CTR: {ctr:.2f}\")\n",
        "print(f\"Diversity Score: {diversity_score:.2f}\")\n",
        "print(f\"PCDI: {pcdi:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exB0-74Vxx2B"
      },
      "source": [
        "The Personalized Click-Through Diversity Index (PCDI) is a metric that combines Click-Through Rate (CTR) and Diversity Score to evaluate recommendation system performance. It considers user engagement (CTR) and the variety of recommended items (Diversity Score).\n",
        "\n",
        "- **Click-Through Rate (CTR)** indicates user interaction with recommendations. Higher CTR suggests relevance to user preferences.\n",
        "- **Diversity Score** measures variety in recommendations. Higher Diversity Score indicates diverse options.\n",
        "\n",
        "**PCDI Value Significance:**\n",
        "- PCDI combines CTR and Diversity Score using weights.\n",
        "- Balanced PCDI suggests a good mix of engagement and diversity.\n",
        "- PCDI > 1 indicates favorable performance.\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **TEAM**\n",
        "1. Harsh - 112115057\n",
        "2. Priyansh - 112115118\n",
        "3. Rohan Kumar - 112115133\n",
        "4. Lingam Saikrishna Seshendra - 112116033\n",
        "5. Santu Dhali - 112116034"
      ],
      "metadata": {
        "id": "XdtUXQ42ZrmY"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}